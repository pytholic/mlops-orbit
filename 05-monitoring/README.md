# Model Monitoring

Very often we see that ML models start to degrade in production. Therefore, we should always monitor our models in production. Some things to monitor are:

- Service health
  - Uptime
  - Memory
  - Latency
- Model performance
  - Accuracy, precision, recall, etc.
- Data quality and integrity
- Data and concept drift
- Performance by segment
- Model bias and fairness
- Outliers
- Explainability

# How to monitor?

## Batch vs Online Serving Models

The way how we deploy a model might influence the way we implement monitoring. In **batch models**, it is easy to compare current distribution(batch data) with a reference distribution (data).
However, when it comes to **non-batch models**, it becomes bit more complicated. Some metrics like missing-values can be computed in real-time. But when it comes to metrics like data drift or model performance, it is much better to generate a batch of data and the calculate these metrics. In such cases, we can use window functions with some window and step size.

## Monitoring Scheme

Our monitoring scheme will be as follows:

- Duration prediction service that will generate predictions
- Prediction logs generated by the service
- Prefect to implement monitoring jobs
- Evidently library as the evaluation layer to calculate some metrics and store in PostgreSQL
- A metrics dashboard with Grafana based on SQL data
